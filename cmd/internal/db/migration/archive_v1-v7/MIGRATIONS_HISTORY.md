# Документация по миграциям БД (v1-v7)

> **Примечание:** Этот документ описывает инкрементальные миграции, которые были объединены в консолидированную версию.  
> Актуальная документация: `/cmd/internal/db/migration/README_CONSOLIDATED.md`

---

## `000001_init_schema.up.sql`

* **Назначение:** "Фундамент"
* **Описание:** Эта миграция создает самую первую, базовую структуру всей базы данных. Она определяет все основные таблицы, необходимые для работы парсера и хранения данных тендеров.

* **Ключевые таблицы:**
  * **Справочники:** `tender_types`, `tender_chapters`, `tender_categories` (создают иерархию для классификации тендеров).
  * **Основные сущности:** `tenders`, `lots`, `proposals` (основная структура тендера: 1 тендер -> N лотов -> N предложений).
  * **Детализация:** `position_items` (самая главная таблица, хранит *каждую* строку из сметы подрядчика с ценами, количеством и т.д.).
  * **RAG (Текст):** `lots_md_documents` (для хранения Markdown-документации) и `lots_chunks` (для хранения "нарезанных" из нее кусков-чанков). **Назначение: RAG по содержанию документов.**
  * **RAG (Каталог):** `catalog_positions` (наш "золотой" справочник "сути" работ). **Назначение: RAG для матчинга и дедупликации позиций.**
* **Важное действие:** Активирует расширение `vector` в PostgreSQL, без которого невозможен семантический поиск.
* **!!! ВНИМАНИЕ !!!** Поле `position_items.catalog_position_id` было создано как `NOT NULL`. Это было **ИСПРАВЛЕНО** в миграции `000004`, где оно стало `NULLABLE`.

---

## `000002_add_rules_and_indexes.up.sql`

* **Назначение:** "Целостность и Скорость"
* **Описание:** Эта миграция не создает новых таблиц, а "дорабатывает" существующие, решая две задачи:

* **1. Целостность данных (Правила `ON DELETE`):**
  * Добавляет правила для внешних ключей. Например, `ON DELETE CASCADE` для `proposals`.
  * **Зачем?** Теперь при удалении `lots` (лота), PostgreSQL автоматически удалит все связанные с ним `proposals` (предложения). Это предотвращает "осиротевшие" данные в БД.

* **2. Скорость (Индексы):**
  * Добавляет специализированные индексы `HNSW` для колонок типа `vector` (в `lots_chunks`).
  * **Зачем?** Ускоряет семантический поиск по *документам*.
  * **!!! ВНИМАНИЕ !!!** HNSW-индекс для `catalog_positions` (`catalog_positions_embedding_idx`), созданный в этой миграции, был **ОТМЕНЕН И ЗАМЕНЕН** на более эффективный *частичный* индекс в миграции `000004`.

---

## `000003_add_raw_data_table.up.sql`

* **Назначение:** "Источник Правды / Аудит"
* **Описание:** Создает одну новую таблицу `tender_raw_data`.

* **Ключевые особенности:**
  * Имеет связь 1-к-1 с таблицей `tenders` (через `tender_id`).
  * Хранит в себе **исходный JSON**, который прислал парсер, в колонке `raw_data` (JSONB).
  * **Зачем?** Это "черный ящик" и "источник правды". Если мы обнаружим ошибку в логике парсинга, нам не нужно заново парсить исходный сайт. Мы можем просто взять JSON из этой таблицы и "перезалить" данные в остальные таблицы, исправив логику Go-сервера.

---

## `000004_add_rag_workflow.up.sql`

* **Назначение:** "Асинхронный RAG-воркфлоу *для позиций каталога*"
* **Описание:** Эта миграция внедряет инфраструктуру для **семантической обработки *позиций* (`catalog_positions`)**. Она позволяет асинхронно создавать эмбеддинги для *названий работ*, находить дубликаты и кэшировать результаты.
* **Примечание:** Этот RAG-воркфлоу *не* связан с RAG по *документам* (который использует `lots_chunks`). Он нужен для очистки и матчинга самого каталога.

* **Компонент 0: `ALTER TABLE "position_items"`...`DROP NOT NULL`**
  * **Что:** Делает `catalog_position_id` в `position_items` `NULLABLE`.
  * **Зачем:** **Критически важно.** Позволяет Go-серверу при "Cache Miss" ставить `NULL`, а Python-воркеру — находить эти `NULL` и асинхронно их заполнять.

* **Компонент 1: `ALTER TABLE "catalog_positions"`...`ADD COLUMN "kind"`**
  * **Что:** Добавляет поле `kind` (тип) с `CHECK`-ограничением (`POSITION`, `HEADER`, `TRASH` и т.д.).
  * **Зачем:** Чтобы Go-сервер мог *немедленно* при парсинге отличать "мусор" от "заголовков" и "работ".

* **Компонент 2: `CREATE TABLE "matching_cache"`**
  * **Что:** Создает таблицу-кэш (словарь) с версионированием (`norm_version`) и TTL (`expires_at`).
  * **Зачем:** Для **скорости**. Чтобы Go-сервер не делал RAG-поиск для "стяжка м200" каждый раз, а мгновенно находил `ID` в этом кэше.

* **Компонент 3: `CREATE TABLE "suggested_merges"`**
  * **Что:** Создает "список задач" для оператора с полями аудита (`decided_by`, `decided_at`) и `CHECK`-ограничением на `status`.
  * **Зачем:** Для **безопасной очистки данных**. Python-воркер (робот) находит дубликаты и кладет их в эту таблицу. Человек-оператор (через админку) подтверждает слияние.

* **Компонент 4: `CREATE INDEX "idx_cp_kind_pos_hnsw"` и `CREATE VIEW "catalog_positions_clean"`**
  * **Что:** Заменяет старый "полный" HNSW-индекс (из `000002`) на *частичный* `WHERE kind = 'POSITION'` и добавляет `VIEW` для него.
  * **Зачем:** RAG-поиск по позициям теперь работает **только** с чистыми данными, что делает его меньше, быстрее и точнее. Код в Go/Python упрощается, т.к. может делать `SELECT ... FROM "catalog_positions_clean"`.

---

## `000005_add_catalog_status.up.sql`

* **Назначение:** "Управление жизненным циклом RAG-индексации"
* **Описание:** Эта миграция добавляет колонку `status` в таблицу `catalog_positions` для отслеживания состояния обработки позиций в RAG-пайплайне. Она дополняет RAG-воркфлоу из миграции `000004`, добавляя возможность различать позиции по их *состоянию* обработки (в дополнение к их *типу* из поля `kind`).

* **Ключевые особенности:**
  * **Поле `status`:** Имеет 5 возможных значений с CHECK-ограничением:
    * `na` (по умолчанию) — "Not Applicable", неприменимо для индексации (используется для HEADER, TRASH и т.д.)
    * `pending_indexing` — позиция ожидает индексации Python-воркером (только для kind = POSITION)
    * `active` — проиндексирована и используется в RAG-поиске
    * `deprecated` — устарела, больше не индексируется
    * `archived` — в архиве, исключена из активной работы
  
  * **Индекс `idx_cp_status_pending`:** Частичный индекс для быстрой выборки "очереди" необработанных позиций. Критичен для эндпоинта `GET /api/v1/catalog/unindexed`.
  
  * **Индекс `idx_cp_status`:** Общий индекс для фильтрации по статусу в админке и отчетах.

* **Интеграция с существующей архитектурой:**
  * **Связь с `kind` (миграция 000004):** Поле `kind` определяет *тип* записи (POSITION/HEADER/TRASH), поле `status` определяет *состояние* обработки. 
    * Записи с `kind = 'POSITION'` должны создаваться с `status = 'pending_indexing'` для попадания в очередь RAG-воркера
    * Записи с `kind IN ('HEADER', 'TRASH', 'LOT_HEADER')` получают `status = 'na'` и никогда не обрабатываются
  
  * **Workflow:** 
    1. Go-сервер создает новую позицию:
       - Если `kind = 'POSITION'` → устанавливает `status = 'pending_indexing'`
       - Если `kind != 'POSITION'` → оставляет `status = 'na'` (по умолчанию)
    2. Python-воркер запрашивает `GET /api/v1/catalog/unindexed` и получает список позиций с `status = 'pending_indexing'`
    3. После создания эмбеддингов, воркер вызывает `POST /api/v1/catalog/mark-indexed`, который обновляет `status` на `active`
    4. Активные позиции участвуют в RAG-поиске через `VIEW catalog_positions_clean`

* **Важное замечание:** Значение по умолчанию `'na'` означает, что существующие записи при применении миграции получат нейтральный статус. Go-сервер должен явно устанавливать `'pending_indexing'` для реальных позиций при их создании.

---

## Операционное обслуживание (Housekeeping)

⚠️ **Примечание:** Эти SQL-запросы актуальны и для консолидированной миграции. См. также раздел "Операционное обслуживание" в `README_CONSOLIDATED.md`.

### Очистка "тухлого" кэша (TTL)

Чтобы таблица `matching_cache` не разрасталась бесконечно и автоматически очищалась от старых записей, необходимо периодически (например, раз в сутки) выполнять следующий запрос:

```sql
-- Удаляет все записи кэша, у которых истек срок жизни (TTL)
DELETE FROM "matching_cache"
WHERE "expires_at" IS NOT NULL AND "expires_at" < now();
```

### Мониторинг RAG-индексации (миграция 000005)

Для контроля работы Python-воркера и состояния каталога рекомендуется периодически проверять распределение позиций по статусам:

```sql
-- Проверка статистики по статусам позиций каталога
SELECT 
    status,
    kind,
    COUNT(*) as count
FROM "catalog_positions"
GROUP BY status, kind
ORDER BY status, kind;

-- Поиск "застрявших" позиций (pending_indexing дольше 24 часов)
SELECT 
    id,
    standard_job_title,
    kind,
    created_at,
    NOW() - created_at as pending_duration
FROM "catalog_positions"
WHERE status = 'pending_indexing' 
  AND kind = 'POSITION'
  AND created_at < NOW() - INTERVAL '24 hours'
ORDER BY created_at
LIMIT 100;

-- Проверка корректности связки kind/status (не должно быть результатов)
SELECT 
    id,
    standard_job_title,
    kind,
    status
FROM "catalog_positions"
WHERE 
    -- Позиции не должны иметь статус 'na'
    (kind = 'POSITION' AND status = 'na')
    OR
    -- Не-позиции не должны иметь статусы индексации
    (kind != 'POSITION' AND status IN ('pending_indexing', 'active'))
LIMIT 100;
```

**Ожидаемая семантика:**
- `kind = 'POSITION'` + `status IN ('pending_indexing', 'active', 'deprecated', 'archived')` — нормально
- `kind IN ('HEADER', 'TRASH', 'LOT_HEADER')` + `status = 'na'` — нормально
- Любые другие комбинации — ошибка в логике приложения
