# Документация по миграциям БД

Этот документ описывает назначение и логику каждого файла миграции в проекте.

---

## `000001_init_schema.up.sql`

* **Назначение:** "Фундамент"
* **Описание:** Эта миграция создает самую первую, базовую структуру всей базы данных. Она определяет все основные таблицы, необходимые для работы парсера и хранения данных тендеров.

* **Ключевые таблицы:**
  * **Справочники:** `tender_types`, `tender_chapters`, `tender_categories` (создают иерархию для классификации тендеров).
  * **Основные сущности:** `tenders`, `lots`, `proposals` (основная структура тендера: 1 тендер -> N лотов -> N предложений).
  * **Детализация:** `position_items` (самая главная таблица, хранит *каждую* строку из сметы подрядчика с ценами, количеством и т.д.).
  * **RAG (Текст):** `lots_md_documents` (для хранения Markdown-документации) и `lots_chunks` (для хранения "нарезанных" из нее кусков-чанков). **Назначение: RAG по содержанию документов.**
  * **RAG (Каталог):** `catalog_positions` (наш "золотой" справочник "сути" работ). **Назначение: RAG для матчинга и дедупликации позиций.**
* **Важное действие:** Активирует расширение `vector` в PostgreSQL, без которого невозможен семантический поиск.
* **!!! ВНИМАНИЕ !!!** Поле `position_items.catalog_position_id` было создано как `NOT NULL`. Это было **ИСПРАВЛЕНО** в миграции `000004`, где оно стало `NULLABLE`.

---

## `000002_add_rules_and_indexes.up.sql`

* **Назначение:** "Целостность и Скорость"
* **Описание:** Эта миграция не создает новых таблиц, а "дорабатывает" существующие, решая две задачи:

* **1. Целостность данных (Правила `ON DELETE`):**
  * Добавляет правила для внешних ключей. Например, `ON DELETE CASCADE` для `proposals`.
  * **Зачем?** Теперь при удалении `lots` (лота), PostgreSQL автоматически удалит все связанные с ним `proposals` (предложения). Это предотвращает "осиротевшие" данные в БД.

* **2. Скорость (Индексы):**
  * Добавляет специализированные индексы `HNSW` для колонок типа `vector` (в `lots_chunks`).
  * **Зачем?** Ускоряет семантический поиск по *документам*.
  * **!!! ВНИМАНИЕ !!!** HNSW-индекс для `catalog_positions` (`catalog_positions_embedding_idx`), созданный в этой миграции, был **ОТМЕНЕН И ЗАМЕНЕН** на более эффективный *частичный* индекс в миграции `000004`.

---

## `000003_add_raw_data_table.up.sql`

* **Назначение:** "Источник Правды / Аудит"
* **Описание:** Создает одну новую таблицу `tender_raw_data`.

* **Ключевые особенности:**
  * Имеет связь 1-к-1 с таблицей `tenders` (через `tender_id`).
  * Хранит в себе **исходный JSON**, который прислал парсер, в колонке `raw_data` (JSONB).
  * **Зачем?** Это "черный ящик" и "источник правды". Если мы обнаружим ошибку в логике парсинга, нам не нужно заново парсить исходный сайт. Мы можем просто взять JSON из этой таблицы и "перезалить" данные в остальные таблицы, исправив логику Go-сервера.

---

## `000004_add_rag_workflow.up.sql`

* **Назначение:** "Асинхронный RAG-воркфлоу *для позиций каталога*"
* **Описание:** Эта миграция внедряет инфраструктуру для **семантической обработки *позиций* (`catalog_positions`)**. Она позволяет асинхронно создавать эмбеддинги для *названий работ*, находить дубликаты и кэшировать результаты.
* **Примечание:** Этот RAG-воркфлоу *не* связан с RAG по *документам* (который использует `lots_chunks`). Он нужен для очистки и матчинга самого каталога.

* **Компонент 0: `ALTER TABLE "position_items"`...`DROP NOT NULL`**
  * **Что:** Делает `catalog_position_id` в `position_items` `NULLABLE`.
  * **Зачем:** **Критически важно.** Позволяет Go-серверу при "Cache Miss" ставить `NULL`, а Python-воркеру — находить эти `NULL` и асинхронно их заполнять.

* **Компонент 1: `ALTER TABLE "catalog_positions"`...`ADD COLUMN "kind"`**
  * **Что:** Добавляет поле `kind` (тип) с `CHECK`-ограничением (`POSITION`, `HEADER`, `TRASH` и т.д.).
  * **Зачем:** Чтобы Go-сервер мог *немедленно* при парсинге отличать "мусор" от "заголовков" и "работ".

* **Компонент 2: `CREATE TABLE "matching_cache"`**
  * **Что:** Создает таблицу-кэш (словарь) с версионированием (`norm_version`) и TTL (`expires_at`).
  * **Зачем:** Для **скорости**. Чтобы Go-сервер не делал RAG-поиск для "стяжка м200" каждый раз, а мгновенно находил `ID` в этом кэше.

* **Компонент 3: `CREATE TABLE "suggested_merges"`**
  * **Что:** Создает "список задач" для оператора с полями аудита (`decided_by`, `decided_at`) и `CHECK`-ограничением на `status`.
  * **Зачем:** Для **безопасной очистки данных**. Python-воркер (робот) находит дубликаты и кладет их в эту таблицу. Человек-оператор (через админку) подтверждает слияние.

* **Компонент 4: `CREATE INDEX "idx_cp_kind_pos_hnsw"` и `CREATE VIEW "catalog_positions_clean"`**
  * **Что:** Заменяет старый "полный" HNSW-индекс (из `000002`) на *частичный* `WHERE kind = 'POSITION'` и добавляет `VIEW` для него.
  * **Зачем:** RAG-поиск по позициям теперь работает **только** с чистыми данными, что делает его меньше, быстрее и точнее. Код в Go/Python упрощается, т.к. может делать `SELECT ... FROM "catalog_positions_clean"`.

---

## Операционное обслуживание (Housekeeping)

Для корректной работы системы в "долгую" необходим фоновый процесс (например, cron job), который будет выполнять регулярную очистку.

### Очистка "тухлого" кэша (TTL)

Чтобы таблица `matching_cache` не разрасталась бесконечно и автоматически очищалась от старых записей, необходимо периодически (например, раз в сутки) выполнять следующий запрос:

```sql
-- Удаляет все записи кэша, у которых истек срок жизни (TTL)
DELETE FROM "matching_cache"
WHERE "expires_at" IS NOT NULL AND "expires_at" < now();